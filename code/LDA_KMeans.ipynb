{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('resume.csv')\n",
    "df = df.dropna(subset=['Resume_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.Resume_str.values.tolist()\n",
    "data = [re.sub(r'\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(r\"\\'\", \"\", sent) for sent in data]\n",
    "data = [re.sub('\\w*\\d\\w*', ' ', sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_words = []\n",
    "for sentence in data:\n",
    "    word = gensim.utils.simple_preprocess(str(sentence), deacc=True)\n",
    "    data_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'VERB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
    "                                stop_words = 'english',\n",
    "                                lowercase = True,\n",
    "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                                max_df = 0.5, \n",
    "                                min_df = 10)\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=20, random_state=20)\n",
    "lda_model.fit(data_vectorized)\n",
    "lda_output = lda_model.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "lda_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = pyLDAvis.sklearn.prepare(lda_model, data_vectorized, vectorizer)\n",
    "pyLDAvis.display(vis_data)\n",
    "# pyLDAvis.save_html(vis_data, 'lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = {}\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    topics_dict[\"Topic\"+str(topic_idx)] = [vectorizer.get_feature_names()[i] for i in topic.argsort()[:-10 - 1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics_to_df = pd.DataFrame(topics_dict).T\n",
    "topics_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics = ['Politics','Aviation','Fitness',\n",
    "          'Services','Teacher','ProductControl',\n",
    "          'IT','Finance','Construction','HR','Arts',\n",
    "          'Developer','Engineerer','Accounting','Chefs',\n",
    "          'Heathcare','Warehouse','Research',\n",
    "          'Sales','Marketing']\n",
    "\n",
    "topics_to_df[\"Topics\"] = topics\n",
    "topics_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters = KMeans(n_clusters=20, random_state=20).fit_predict(lda_output)\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=2)\n",
    "lda_output_svd = svd_model.fit_transform(lda_output)\n",
    "\n",
    "x = lda_output_svd[:, 0]\n",
    "y = lda_output_svd[:, 1]\n",
    "\n",
    "print(\"Weights:\", np.round(svd_model.components_, 2))\n",
    "\n",
    "print(\"Variance:\", np.round(svd_model.explained_variance_ratio_, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(x, y, c=clusters)\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.title(\"SVD of Topic Clusters\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_names = ['Topic' + str(i) for i in range(lda_model.n_components)]\n",
    "topic_keywords = pd.DataFrame(lda_model.components_)\n",
    "topic_keywords.columns = vectorizer.get_feature_names()\n",
    "topic_keywords.index = topic_names\n",
    "\n",
    "keywords = np.array(vectorizer.get_feature_names())\n",
    "topic_keywords = []\n",
    "for topic_weights in lda_model.components_:\n",
    "    top_keyword_locs = (-topic_weights).argsort()[:10]\n",
    "    topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "                             \n",
    "topic_keywords = pd.DataFrame(topic_keywords)\n",
    "topic_keywords.columns = ['Word '+str(i) for i in range(topic_keywords.shape[1])]\n",
    "topic_keywords.index = ['Topic '+str(i) for i in range(topic_keywords.shape[0])]\n",
    "\n",
    "topic_keywords[\"Topics\"]=topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def predict_topic(text, nlp=nlp):\n",
    "    \n",
    "    words = []\n",
    "    for sentence in text:\n",
    "        word = gensim.utils.simple_preprocess(str(sentence), deacc=True)\n",
    "        words.append(word)\n",
    "    \n",
    "    lemm = lemmatization(words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "    vector = vectorizer.transform(lemm)\n",
    "    \n",
    "    topic_scores = lda_model.transform(vector)\n",
    "    topic = topic_keywords.iloc[np.argmax(topic_scores), 1:14].values.tolist()\n",
    "    \n",
    "    infer_topic = topic_keywords.iloc[np.argmax(topic_scores), -1]\n",
    "    \n",
    "    return infer_topic, topic, topic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = [[\"Managing schedules for interviews and deep search for potential worker.\"],\n",
    "         [\"Head chef for 8 years and cook over 100 dishes a day under fast paced environment.\"],\n",
    "         [\"Developing software on daily bases with tight deadlines weekly.\"],\n",
    "         [\"Objective : Competent, compassionate, and empathetic Staff Nurse with background experience in mental health. Meets responsibility in patient safety, medication safety, coordination of care, and prioritization. Works well under pressure, persistent, determined, and goal oriented. Emotional stability to cope with human suffering, emergencies and other stresses. Offering leadership qualities with a positive attitude. Motivated, hardworking, organized, focused and dedicated. To embrace a career opportunity where my healthcare background and education would be conducive to achieving all goals.\"]]\n",
    "\n",
    "for text in mytext:\n",
    "    infer_topic, topic, prob_scores = predict_topic(text)\n",
    "\n",
    "    print(\"------------\")\n",
    "    print(topic)\n",
    "    print(infer_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
